{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import PyPDF2 as pdf\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "class NLPProcessor:\n",
    "    def __init__(self, model_name=\"en_core_web_sm\"):\n",
    "        self.nlp = spacy.load(model_name, disable=[\"parser\", \"ner\"])\n",
    "        \n",
    "    def _remove_symbols(self, text):\n",
    "         text = re.sub(r'[^\\w]', ' ', text)\n",
    "         text = re.sub(' +', ' ', text)\n",
    "         return text\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        tokens = [token.text for token in doc]\n",
    "        return tokens\n",
    "\n",
    "    def remove_stopwords(self, tokens):\n",
    "        doc = self.nlp(\" \".join(tokens))\n",
    "        filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "        return filtered_tokens\n",
    "\n",
    "    def lemmatize(self, tokens):\n",
    "        doc = self.nlp(\" \".join(tokens))\n",
    "        lemmas = [token.lemma_ for token in doc]\n",
    "        return lemmas\n",
    "    \n",
    "    @staticmethod       \n",
    "    def _filter_text(text, n_words=10):\n",
    "        if len(text.split()) < n_words:\n",
    "            return ''\n",
    "        return text\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        # text = self._remove_symbols(text)\n",
    "        tokens = self.tokenize(text)\n",
    "        filtered_tokens = self.remove_stopwords(tokens)\n",
    "        lemmas = self.lemmatize(filtered_tokens)\n",
    "        preprocessed_text = \" \".join(lemmas)\n",
    "        # preprocessed_text = self._filter_text(text=preprocessed_text)\n",
    "        return preprocessed_text\n",
    "\n",
    "\n",
    "def _clause_extract(text, min_words=30):\n",
    "    processor = NLPProcessor()\n",
    "    text_list = [x.strip() for x in text.split('\\n\\n')]\n",
    "    para_list = []\n",
    "    for text in text_list:\n",
    "        processed_text = processor.preprocess_text(text)\n",
    "        # print(len(processed_text))\n",
    "        if len(processed_text) > min_words:\n",
    "            para_list.append(processed_text)\n",
    "            \n",
    "    return para_list\n",
    "\n",
    "res = _clause_extract(data)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b35a4812b94cbdafdef5f95e0980e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d7c3a878f34a6592d8af8bf53ccac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8811f7b93d5a42e08eca5fad7bb69fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d902a275f059415c9a66c3d44011e091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a042220fe6494faa597640818b68a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89b31da3fab4b5386cca1f070c3f666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a99405cf544a28a80a9aeb1570cd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496326c545264a21a5584bd7f251cc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c4f6b4b89d4e3abe9ef199c25ab901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d144985dd4834013b8bdc912b339fcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbadc902849446038bfa46bfdf349cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( ) request SEC amendment registration statement , prospectus , statement additional information effect additional information ; ( b ) event issuance SEC stop order suspend effectiveness registration statement , prospectus , statement additional information effect initiation proceeding purpose ; ( c ) happen event make untrue statement material fact registration statement , prospectus , statement additional information effect require make change registration statement , prospectus , statement additional information order statement mislead ; ( d ) action SEC respect amendment registration statement , prospectus , statement additional information time time file SEC . SECTION 7 . TERM AGREEMENT Section 7.1 Agreement shall continue January 18 , 2022 , shall continue automatically successive annual period end January 18th year , provide continuance specifically approve annually ( ) Fund Board Trustees ( b ) vote majority ( define 1940 Act ) Fund Trustees interested person ( define 1940 Act ) fund direct indirect financial interest operation Plan , Agreement , agreement relate Plan ( \" Qualified Trustees \" ) , vote cast person meeting call purpose voting approval . agreement terminable respect Fund , penalty , ( ) 60 day ' write notice , vote majority Qualified Trustees vote majority ( define 1940 Act ) outstanding voting securities Fund ( b ) 90 day ' write notice Integrity . agreement terminate automatically event assignment ( define 1940 Act ) . section 8 . MISCELLANEOUS Section 8.1 Fund recognize governor , officer , employee Integrity time time serve director , officer , employee corporation business trust ( include investment company ) Integrity affiliate enter distribution agreement corporation trust . section 8.2 expressly agree obligation Fund hereunder shall bind trustee , shareholder , nominee , officer , agent , employee Fund , personally , bind property Fund . execution delivery Agreement authorize Trustees sign authorized officer Fund , acting , authorization trustees execution delivery officer shall deem individually impose liability personally , shall bind property Fund . 7\n"
     ]
    }
   ],
   "source": [
    "\"\"\"spacy pretrained model downlaod: \n",
    "python -m spacy download en_core_web_sm\n",
    "\"\"\"\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import PyPDF2 as pdf\n",
    "from pathlib import Path\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "class NLPProcessor:\n",
    "    def __init__(self, model_name=\"en_core_web_sm\"):\n",
    "        self.nlp = spacy.load(model_name, disable=[\"parser\", \"ner\"])\n",
    "        \n",
    "    def _remove_symbols(self, text):\n",
    "         text = re.sub(r'[^\\w]', ' ', text)\n",
    "         text = re.sub(' +', ' ', text)\n",
    "         return text\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        tokens = [token.text for token in doc]\n",
    "        return tokens\n",
    "\n",
    "    def remove_stopwords(self, tokens):\n",
    "        doc = self.nlp(\" \".join(tokens))\n",
    "        filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "        return filtered_tokens\n",
    "\n",
    "    def lemmatize(self, tokens):\n",
    "        doc = self.nlp(\" \".join(tokens))\n",
    "        lemmas = [token.lemma_ for token in doc]\n",
    "        return lemmas\n",
    "    \n",
    "    @staticmethod       \n",
    "    def _filter_text(text, n_words=10):\n",
    "        if len(text.split()) < n_words:\n",
    "            return ''\n",
    "        return text\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        # text = self._remove_symbols(text)\n",
    "        tokens = self.tokenize(text)\n",
    "        filtered_tokens = self.remove_stopwords(tokens)\n",
    "        lemmas = self.lemmatize(filtered_tokens)\n",
    "        preprocessed_text = \" \".join(lemmas)\n",
    "        # preprocessed_text = self._filter_text(text=preprocessed_text)\n",
    "        return preprocessed_text\n",
    "\n",
    "\n",
    "def clause_extract(text, min_words=30):\n",
    "    processor = NLPProcessor()\n",
    "    text_list = [x.strip() for x in text.split('\\n\\n')]\n",
    "    para_list = []\n",
    "    for text in text_list:\n",
    "        processed_text = processor.preprocess_text(text)\n",
    "        if len(processed_text) > min_words:\n",
    "            para_list.append(processed_text)\n",
    "            \n",
    "    return para_list\n",
    "\n",
    "\n",
    "class VectorDB:\n",
    "    def __init__(self, model_id=None) -> None:\n",
    "        model_id = model_id if model_id else  \"all-MiniLM-L6-v2\"\n",
    "        self.embedding = HuggingFaceEmbeddings(model_name=model_id)\n",
    "\n",
    "    def _init_db(self, text_list):\n",
    "        self.db = Chroma.from_texts(text_list, embedding=self.embedding)\n",
    "        \n",
    "    def query(self, query, topk=1):\n",
    "        docs = self.db.similarity_search(query, k=topk)\n",
    "        if len(docs):\n",
    "            return docs[0].page_content\n",
    "\n",
    "\n",
    "def _load_contract(file_name, file_path=None):\n",
    "    if not file_path:\n",
    "        file_path = 'contracts'\n",
    "    with open(os.path.join(file_path, file_name), 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def _load_json(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        json_data = json.loads(f.read())\n",
    "    return json_data\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \"read the contrat and init the vectordb, get user query, and get similar paragraph, use this to do prompt constraction.\"\n",
    "contract_path = 'contracts'\n",
    "contract_file = os.listdir(contract_path)[0]\n",
    "\n",
    "text = _load_contract(contract_file)\n",
    "para_list = clause_extract(text=text)\n",
    "clause_sim_dict = _load_json('./similar_clause_dict.json')\n",
    "\n",
    "db = VectorDB()\n",
    "db._init_db(text_list=para_list)\n",
    "\n",
    "# this should be clause name, \n",
    "# todo:at least we should ensure that this key words should be in the text.\n",
    "query='Notice Period to Terminate Renewal'\n",
    "if query not in clause_sim_dict:\n",
    "    print(\"The clause: {} is not supported! Stop\".format(query))\n",
    "    sys.exit(-1)\n",
    "else:\n",
    "    similar_clauses = clause_sim_dict.get(query, [])\n",
    "    similar_clauses.append(query)\n",
    "    # to get the query, should also get some related clause names based on the dictionary.\n",
    "    query = ' & '.join(similar_clauses)\n",
    "    related_para = db.query(query=query)\n",
    "    print(related_para)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23845"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_list = clause_extract(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb = VectorDB()\n",
    "vb._init_db(para_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DISTRIBUTION AND SERVICES AGREEMENT January 18, 2020 This is to confirm that, in consideration of th'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DISTRIBUTION SERVICES AGREEMENT January 18 , 2020 confirm , consideration agreement hereinafter contain , undersigned , Integrity Short Term Government Fund , ( \" Fund \" ) , open - end , diversify , management investment company organize series Integrity Funds , Delaware statutory trust , agree Integrity Funds Distributor , LLC , ( \" Integrity \" ) , shall , period distribution agreement ( \" Agreement \" ) , principal underwriter share issue Fund , include class share authorize ( \" share \" ) . section 1 . SERVICES UNDERWRITER Section 1.1 Integrity act principal underwriter distribution Shares cover registration statement , prospectus , statement additional information effect Fund ( \" Registration Statement \" ) Securities Act 1933 , amend ( \" 1933 Act \" ) , Investment Company Act 1940 , amend ( \" 1940 Act \" ) . section 1.2 Integrity agree use good effort solicit order sale Shares public offering price , determined accordance Registration Statement , undertake advertising promotion believe reasonable connection solicitation . integrity shall order Shares Fund extent shall received purchase order . section 1.3 activity integrity underwriter share shall comply applicable law , rule , regulation , include , limitation , rule regulation adopt Securities Exchange Commission ( \" SEC \" ) security association registered Securities Exchange Act 1934 Fund Registration Statement . section 1.4 Integrity provide person normal business hour respond telephone question concern Fund . section 1.5 Integrity acknowledge , judgment Fund officer action warrant reason , include , limitation , market , economic , political condition , officer decline accept order , sale , share time officer deem advisable accept order sale . section 1.6 Integrity shall deem independent contractor , specifically provide authorize , shall authority act represent Fund . integrity act behalf principal choose enter sell agreement select dealer . integrity allow commission concession dealer amount Integrity shall determine time time , set forth Fund Registration Statement . determine Integrity Fund time time , commission concession shall uniform dealer . share sell dealer shall resale dealer public offer price(s ) set forth Fund current Registration Statement . price Fund shall receive share purchase Fund shall net asset value determine public offering price applicable sale share .'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vb.query(query='DISTRIBUTION AND SERVICES AGREEMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clauses_support.txt', 'r') as f:\n",
    "    c_list = f.readlines()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = int(len(c_list) / 10)\n",
    "\n",
    "r_list = []\n",
    "\n",
    "for i in range(p):\n",
    "    r_list.append(c_list[i * 10: (i + 1) * 10])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Name, Parties, Agreement Date, Effective Date, Expiration Date, Renewal Term, Notice Period to Terminate Renewal, Governing Law, Most Favored Nation, Non-Compete\n",
      "Exclusivity, No-Solicit of Customers, Competitive Restriction Exception, No-Solicit of Employees, Non-Disparagement, Termination for Convenience, Rofr/Rofo/Rofn, Change of Control, Anti-Assignment, Revenue/Profit Sharing\n",
      "Price Restrictions, Minimum Commitment, Volume Restriction, IP Ownership Assignment, Joint IP Ownership, License Grant, Non-Transferable License, Affiliate License-Licensor, Affiliate License-Licensee, Unlimited/All-You-Can-Eat-License\n",
      "Irrevocable or Perpetual License, Source Code Escrow, Post-Termination Services, Audit Rights, Uncapped Liability, Cap on Liability, Liquidated Damages, Warranty Duration, Insurance, Covenant Not to Sue\n"
     ]
    }
   ],
   "source": [
    "for x in r_list:\n",
    "    print(', '.join([t.replace('\\n', '') for t in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Name,Parties,Agreement Date,Effective Date,Expiration Date,Renewal Term,Notice Period to Terminate Renewal,Governing Law,Most Favored Nation,Non-Compete,Exclusivity,No-Solicit of Customers,Competitive Restriction Exception,No-Solicit of Employees,Non-Disparagement,Termination for Convenience,Rofr/Rofo/Rofn,Change of Control,Anti-Assignment,Revenue/Profit Sharing,Price Restrictions,Minimum Commitment,Volume Restriction,IP Ownership Assignment,Joint IP Ownership,License Grant,Non-Transferable License,Affiliate License-Licensor,Affiliate License-Licensee,Unlimited/All-You-Can-Eat-License,Irrevocable or Perpetual License,Source Code Escrow,Post-Termination Services,Audit Rights,Uncapped Liability,Cap on Liability,Liquidated Damages,Warranty Duration,Insurance,Covenant Not to Sue,Third Party Beneficiary\n"
     ]
    }
   ],
   "source": [
    "print(','.join([t.replace('\\n', '') for t in c_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
